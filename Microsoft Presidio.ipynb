{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586f1a95-bcad-4804-a2a6-df1bf98fade4",
   "metadata": {},
   "source": [
    "Presidio (Origin from Latin praesidium ‘protection, garrison’) helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text and images such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c5f11a-519b-4699-9f24-153f1f3c94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: presidio_analyzer in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (2.2.353)\n",
      "Requirement already satisfied: phonenumbers<9.0.0,>=8.12 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from presidio_analyzer) (8.13.30)\n",
      "Requirement already satisfied: tldextract in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from presidio_analyzer) (5.1.1)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from presidio_analyzer) (3.7.4)\n",
      "Requirement already satisfied: pyyaml in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from presidio_analyzer) (6.0.1)\n",
      "Requirement already satisfied: regex in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from presidio_analyzer) (2023.12.25)\n",
      "Requirement already satisfied: jinja2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.1.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (6.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.3.4)\n",
      "Requirement already satisfied: setuptools in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (65.6.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.6.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.9.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.1.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.2.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (23.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from tldextract->presidio_analyzer) (3.13.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from tldextract->presidio_analyzer) (2.0.0)\n",
      "Requirement already satisfied: idna in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from tldextract->presidio_analyzer) (3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.16.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install presidio_analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5781e0",
   "metadata": {},
   "source": [
    "#### Simple flow\n",
    "A simple call to Presidio Analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3bc8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[type: PERSON, start: 16, end: 21, score: 0.85, type: PHONE_NUMBER, start: 46, end: 58, score: 0.75]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "text = \"His name is Mr. Jones and his phone number is 212-555-5555\"\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer_results = analyzer.analyze(text=text, language=\"en\")\n",
    "\n",
    "print(analyzer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea8dfa",
   "metadata": {},
   "source": [
    "### Example 1: Deny-list based PII recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c48c13",
   "metadata": {},
   "source": [
    "in this example, I will pass a short list of tokens which should be marked as PII if detected. First, let's define the tokens we want to treat as PII. In this case it would be a list of titles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164e5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = [\n",
    "    \"Sir\",\n",
    "    \"Ma'am\",\n",
    "    \"Madam\",\n",
    "    \"Mr.\",\n",
    "    \"Mrs.\",\n",
    "    \"Ms.\",\n",
    "    \"Miss\",\n",
    "    \"Dr.\",\n",
    "    \"Professor\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b2d38",
   "metadata": {},
   "source": [
    "Second, let's create a **PatternRecognizer** which would scan for those titles, by passing a deny_list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f023fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import PatternRecognizer\n",
    "\n",
    "titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d047fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " [type: TITLE, start: 10, end: 19, score: 1.0]\n"
     ]
    }
   ],
   "source": [
    "## Calling our recognizer directly\n",
    "text1 = \"I suspect Professor Plum, in the Dining Room, with the candlestick\"\n",
    "result = titles_recognizer.analyze(text1, entities=[\"TITLE\"])\n",
    "print(f\"Result:\\n {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf318db",
   "metadata": {},
   "source": [
    "I can add another List od recognizers used by the Presidio **AnalyzerEngine**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aad7c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90f5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.registry.add_recognizer(titles_recognizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151418c1",
   "metadata": {},
   "source": [
    "**LEARNING POINT** - here, at initialization, Presidio loads all available recognizers, including the NLPEngine used to detect enitites, and extract tokens, lemmas and other linguistic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc75e785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results : \n",
      "[type: TITLE, start: 10, end: 19, score: 1.0, type: PERSON, start: 20, end: 24, score: 0.85]\n"
     ]
    }
   ],
   "source": [
    "results = analyzer.analyze(text =text1, language=\"en\")\n",
    "print(\"Results : \")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8323476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified these PII entities:\n",
      "- Professor as TITLE\n",
      "- Plum as PERSON\n"
     ]
    }
   ],
   "source": [
    "print(\"Identified these PII entities:\")\n",
    "for result in results:\n",
    "    print(f\"- {text1[result.start:result.end]} as {result.entity_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9607000",
   "metadata": {},
   "source": [
    "As expected, both the name \"Plum\" and the title were identified as PII."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7dba3",
   "metadata": {},
   "source": [
    "### Example 2: Regular-expressions based PII recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f1dc8",
   "metadata": {},
   "source": [
    "This is another simple recognizer we can add is based on regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15e9fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "[type: NUMBER, start: 10, end: 13, score: 0.5]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import Pattern, PatternRecognizer\n",
    "\n",
    "# Define the regex pattern in a Presidio `Pattern` object:\n",
    "numbers_pattern = Pattern(name=\"numbers_pattern\", regex=\"\\d+\", score=0.5)\n",
    "\n",
    "# Define the recognizer with one or more patterns\n",
    "number_recognizer = PatternRecognizer(\n",
    "    supported_entity=\"NUMBER\", patterns=[numbers_pattern]\n",
    ")\n",
    "\n",
    "text2 = \"I live in 510 Broad st.\"\n",
    "\n",
    "numbers_result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"])\n",
    "\n",
    "print(\"Result:\")\n",
    "print(numbers_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9675b5f",
   "metadata": {},
   "source": [
    "**LEARNING CURVE**: One can add different REGEX expression and distinguish result accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86ae8b",
   "metadata": {},
   "source": [
    "### Example 3: Rule based logic recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee85b9",
   "metadata": {},
   "source": [
    "detecting numbers in either numerical or alphabetic (e.g. Forty five) form:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "071afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from presidio_analyzer import EntityRecognizer, RecognizerResult\n",
    "from presidio_analyzer.nlp_engine import NlpArtifacts\n",
    "\n",
    "\n",
    "class NumbersRecognizer(EntityRecognizer):\n",
    "\n",
    "    expected_confidence_level = 0.7  # expected confidence level for this recognizer\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"No loading is required.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def analyze(\n",
    "        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n",
    "    ) -> List[RecognizerResult]:\n",
    "        \"\"\"\n",
    "        Analyzes test to find tokens which represent numbers (either 123 or One Two Three).\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        # iterate over the spaCy tokens, and call `token.like_num`\n",
    "        for token in nlp_artifacts.tokens:\n",
    "            if token.like_num:\n",
    "                result = RecognizerResult(\n",
    "                    entity_type=\"NUMBER\",\n",
    "                    start=token.idx,\n",
    "                    end=token.idx + len(token),\n",
    "                    score=self.expected_confidence_level,\n",
    "                )\n",
    "                results.append(result)\n",
    "        return results\n",
    "\n",
    "# Instantiate the new NumbersRecognizer:\n",
    "new_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527c665",
   "metadata": {},
   "source": [
    "Since this recognizer requires the NlpArtifacts, we would have to call it as part of the AnalyzerEngine flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc97072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "type: PERSON, start: 0, end: 7, score: 0.85\n",
      "type: NUMBER, start: 17, end: 21, score: 0.7\n",
      "type: NUMBER, start: 22, end: 24, score: 0.7\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "\n",
    "text3 = \"Roberto lives in Five 10 Broad st.\"\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.registry.add_recognizer(new_numbers_recognizer)\n",
    "\n",
    "numbers_results2 = analyzer.analyze(text=text3, language=\"en\")\n",
    "print(\"Results:\")\n",
    "print(\"\\n\".join([str(res) for res in numbers_results2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace0d5d",
   "metadata": {},
   "source": [
    "### Example 4: Supporting new models and languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58929bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from es-core-news-md==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.6.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (23.0)\n",
      "Requirement already satisfied: setuptools in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (65.6.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ashleshkhajbage/Library/r-miniconda-arm64/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.1.5)\n",
      "Installing collected packages: es-core-news-md\n",
      "Successfully installed es-core-news-md-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Results from Spanish request:\n",
      "[type: PERSON, start: 13, end: 19, score: 0.85]\n",
      "Results from English request:\n",
      "[type: PERSON, start: 11, end: 17, score: 0.85]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "\n",
    "# import spacy\n",
    "# spacy.cli.download(\"es_core_news_md\")\n",
    "\n",
    "# Create configuration containing engine name and models\n",
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [\n",
    "        {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n",
    "        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create NLP engine based on configuration\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine_with_spanish = provider.create_engine()\n",
    "\n",
    "# Pass the created NLP engine and supported_languages to the AnalyzerEngine\n",
    "analyzer = AnalyzerEngine(\n",
    "    nlp_engine=nlp_engine_with_spanish, supported_languages=[\"en\", \"es\"]\n",
    ")\n",
    "\n",
    "# Analyze in different languages\n",
    "results_spanish = analyzer.analyze(text=\"Mi nombre es Morris\", language=\"es\")\n",
    "print(\"Results from Spanish request:\")\n",
    "print(results_spanish)\n",
    "\n",
    "results_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\n",
    "print(\"Results from English request:\")\n",
    "print(results_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a926e",
   "metadata": {},
   "source": [
    "### Example 5: Leveraging context words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8dbe5",
   "metadata": {},
   "source": [
    "US_ZIP_CODE recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58d7535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " [type: US_ZIP_CODE, start: 15, end: 20, score: 0.01]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import (\n",
    "    Pattern,\n",
    "    PatternRecognizer,\n",
    "    RecognizerRegistry,\n",
    "    AnalyzerEngine,\n",
    ")\n",
    "\n",
    "# Define the regex pattern\n",
    "regex = r\"(\\b\\d{5}(?:\\-\\d{4})?\\b)\"  # very weak regex pattern\n",
    "zipcode_pattern = Pattern(name=\"zip code (weak)\", regex=regex, score=0.01)\n",
    "\n",
    "# Define the recognizer with the defined pattern\n",
    "zipcode_recognizer = PatternRecognizer(\n",
    "    supported_entity=\"US_ZIP_CODE\", patterns=[zipcode_pattern]\n",
    ")\n",
    "\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizer(zipcode_recognizer)\n",
    "analyzer = AnalyzerEngine(registry=registry)\n",
    "\n",
    "# Test\n",
    "results = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\n",
    "\n",
    "print(f\"Result:\\n {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090b396",
   "metadata": {},
   "source": [
    "So this is working, but would catch any 5 digit string. This is why we set the score to 0.01. Let's use context words to increase score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbffae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "[type: US_ZIP_CODE, start: 15, end: 20, score: 0.4]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import PatternRecognizer,  AnalyzerEngine, RecognizerRegistry\n",
    "\n",
    "\n",
    "zipcode_recognizer_w_context  = PatternRecognizer(\n",
    "    supported_entity=\"US_ZIP_CODE\",\n",
    "    patterns=[zipcode_pattern],\n",
    "    context=[\"zip\",\"zipcode\"],\n",
    ")\n",
    "\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizer(zipcode_recognizer_w_context)\n",
    "analyzer = AnalyzerEngine(registry=registry)\n",
    "\n",
    "# Test\n",
    "results = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\n",
    "print(\"Result:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a8aad",
   "metadata": {},
   "source": [
    "**LEARNING CURVE **- \n",
    "1. **AnalyzerEngine** will create **LemmaContextAwareEnhancer** by default if not passed, which will enhance score of each matched result if its recognizer holds context words and the lemma of those words are found in the surroundings of the matched entity.\n",
    "\n",
    "2. since the **LemmaContextAwareEnhancer** default context similarity factor is 0.35 and default minimum score with context similarity is 0.4\n",
    "\n",
    "3. We can change that by passing other values to the context_similarity_factor and min_score_with_context_similarity parameters of the LemmaContextAwareEnhancer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af27ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "[type: US_ZIP_CODE, start: 15, end: 20, score: 0.46]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "\n",
    "context_aware_enhancer = LemmaContextAwareEnhancer(\n",
    "    context_similarity_factor=0.45, min_score_with_context_similarity=0.4\n",
    ")\n",
    "\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizer(zipcode_recognizer_w_context)\n",
    "analyzer = AnalyzerEngine(\n",
    "    registry=registry, context_aware_enhancer=context_aware_enhancer\n",
    ")\n",
    "\n",
    "# Test\n",
    "results = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\n",
    "print(\"Result:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15f360",
   "metadata": {},
   "source": [
    "**LEARNING CURVE**: \n",
    "- In addition to surrounding words, **additional context words could be passed on the request level**. This is useful when there is context coming from metadata such as column names or a specific user input. In the following example, notice how the \"zip\" context word doesn't appear in the text but still enhances the confidence score from 0.01 to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94265bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result\n",
      "[type: US_ZIP_CODE, start: 11, end: 16, score: 0.4]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer\n",
    "import pprint\n",
    "# Define the recognizer with the defined pattern and context words\n",
    "zipcode_recognizer = PatternRecognizer(\n",
    "    supported_entity=\"US_ZIP_CODE\",\n",
    "    patterns=[zipcode_pattern],\n",
    "    context=[\"zip\", \"zipcode\"],\n",
    ")\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizer(zipcode_recognizer)\n",
    "analyzer = AnalyzerEngine(registry=registry)\n",
    "\n",
    "# Test with an example record having a column name which could be injected as context\n",
    "record = {\"column_name\": \"zip\", \"text\": \"My code is 90210\"}\n",
    "\n",
    "result = analyzer.analyze(\n",
    "    text=record[\"text\"], language=\"en\", context=[record[\"column_name\"]], return_decision_process=True\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Result\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0748897",
   "metadata": {},
   "source": [
    "### Example 6 : Tracing Decision Process  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c5228",
   "metadata": {},
   "source": [
    "Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain:\n",
    "\n",
    "- Which recognizer detected the entity\n",
    "- Which regex pattern was used\n",
    "- Interpretability mechanisms in ML models\n",
    "- Which context words improved the score\n",
    "- Confidence scores before and after each step And more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2ba73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision process output:\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "import pprint\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "\n",
    "results = analyzer.analyze(\n",
    "    text=\"My zip code is 90210\", language=\"en\", return_decision_process=True\n",
    ")\n",
    "\n",
    "#decision_process = results[0].analysis_explanation\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(\"Decision process output:\\n\")\n",
    "pp.pprint(results)\n",
    "#pp.pprint(results.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200b801",
   "metadata": {},
   "source": [
    "### Example 7: Creating no-code pattern recognizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "045ec914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type: TITLE, start: 0, end: 3, score: 1.0,\n",
       " type: TITLE, start: 8, end: 12, score: 1.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
    "\n",
    "yaml_file = \"/Users/ashleshkhajbage/Documents/GitHub/PII-Data-Detection/example_recognizers.yaml\"\n",
    "registry = RecognizerRegistry()\n",
    "registry.add_recognizers_from_yaml(yaml_file)\n",
    "\n",
    "analyzer = AnalyzerEngine(registry=registry)\n",
    "analyzer.analyze(text=\"Mr. and Mrs. Smith\", language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d89094",
   "metadata": {},
   "source": [
    "This example adds the new recognizers to the predefined recognizers in Presidio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb86d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type: PERSON, start: 4, end: 8, score: 0.85]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
    "\n",
    "yaml_file = \"/Users/ashleshkhajbage/Documents/GitHub/PII-Data-Detection/example_recognizers.yaml\"\n",
    "registry = RecognizerRegistry()\n",
    "registry.load_predefined_recognizers()  # Loads all the predefined recognizers (Credit card, phone number etc.)\n",
    "\n",
    "registry.add_recognizers_from_yaml(yaml_file)\n",
    "\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.analyze(text=\"Mr. Plum wrote a book\", language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
